{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5c95da",
   "metadata": {},
   "source": [
    "# Module 10-Scraping a Website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd927d7",
   "metadata": {},
   "source": [
    "- Author: brandon chiazza\n",
    "- version 2.0\n",
    "\n",
    "We will be creating a web scraper to parse a table from the Charities Bureau Website. From the website: “All \n",
    "charitable organizations operating in New York State are required by law to register and file annual financial reports \n",
    "with the Attorney General's Office. This includes any organization that conducts charitable activities, holds property \n",
    "that is used for charitable purposes, or solicits financial or other contributions.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c24a08",
   "metadata": {},
   "source": [
    "# Part I. Create web-scraper to load csv file into S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcef91dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.19.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.26.9)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.25.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.17->selenium)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.17->selenium)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.Collecting exceptiongroup (from trio~=0.17->selenium)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyter-server 1.13.5 requires pywinpty<2; os_name == \"nt\", but you have pywinpty 2.0.2 which is incompatible.\n",
      "spyder 5.1.5 requires pyqt5<5.13, but you have pyqt5 5.15.10 which is incompatible.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, but you have pyqtwebengine 5.15.6 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading exceptiongroup-1.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Downloading selenium-4.19.0-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 10.5/10.5 MB 27.3 MB/s eta 0:00:00\n",
      "Downloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
      "   --------------------------------------- 467.2/467.2 kB 28.6 MB/s eta 0:00:00\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading exceptiongroup-1.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 58.3/58.3 kB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sniffio, h11, exceptiongroup, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.2.0\n",
      "    Uninstalling sniffio-1.2.0:\n",
      "      Successfully uninstalled sniffio-1.2.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 21.4.0\n",
      "    Uninstalling attrs-21.4.0:\n",
      "      Successfully uninstalled attrs-21.4.0\n",
      "Successfully installed attrs-23.2.0 exceptiongroup-1.2.0 h11-0.14.0 outcome-1.3.0.post0 selenium-4.19.0 sniffio-1.3.1 trio-0.25.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe55ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.27.1)\n",
      "Collecting python-dotenv (from webdriver-manager)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from webdriver-manager) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from packaging->webdriver-manager) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hegde\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Downloading webdriver_manager-4.0.1-py2.py3-none-any.whl (27 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a10bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "777ad81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>NY Reg #</th>\n",
       "      <th>EIN</th>\n",
       "      <th>Registrant Type</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Forever Captain Poodaman\" The Ahmad Butler Fo...</td>\n",
       "      <td>48-07-16</td>\n",
       "      <td>843800926</td>\n",
       "      <td>NFP</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Incredibly Blessed\" Inc</td>\n",
       "      <td>49-54-61</td>\n",
       "      <td>842071758</td>\n",
       "      <td>NFP</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"R\" S.U.C.C.E.S.S. Foundation Inc.</td>\n",
       "      <td>49-06-59</td>\n",
       "      <td>874012670</td>\n",
       "      <td>NFP</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Studio 5404\" Inc.</td>\n",
       "      <td>44-39-58</td>\n",
       "      <td>463180470</td>\n",
       "      <td>NFP</td>\n",
       "      <td>MASSAPAQUA</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"THEY ARE HAITIAN\" FUND, INC.</td>\n",
       "      <td>20-63-46</td>\n",
       "      <td>300170128</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HUDSON</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"Y\" Dive, Inc.</td>\n",
       "      <td>48-45-01</td>\n",
       "      <td>854252095</td>\n",
       "      <td>NFP</td>\n",
       "      <td>SAINT ALBANS</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(ASMA) American Syrian Multicultural Associati...</td>\n",
       "      <td>42-84-63</td>\n",
       "      <td>273130182</td>\n",
       "      <td>NFP</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>#FeedHamburg</td>\n",
       "      <td>48-37-35</td>\n",
       "      <td>854150318</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HAMBURG</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#HicksStrong Inc.</td>\n",
       "      <td>48-10-48</td>\n",
       "      <td>842612081</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CLIFTON PARK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#WalkAway Foundation</td>\n",
       "      <td>47-15-80</td>\n",
       "      <td>832820906</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CARLSBAD</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>04/11 10:17 PM test</td>\n",
       "      <td>47-13-95</td>\n",
       "      <td>206256427</td>\n",
       "      <td>NFP</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1/20/21 Action Fund</td>\n",
       "      <td>46-99-13</td>\n",
       "      <td>832210730</td>\n",
       "      <td>NFP</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10/40 Connections, Inc.</td>\n",
       "      <td>45-70-15</td>\n",
       "      <td>621825230</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HIXSON</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000 Feet Project, Inc</td>\n",
       "      <td>45-00-14</td>\n",
       "      <td>473820859</td>\n",
       "      <td>NFP</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1000 Islands Hose Haulers</td>\n",
       "      <td>45-38-38</td>\n",
       "      <td>454570241</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CARTHAGE</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Organization Name  NY Reg #        EIN  \\\n",
       "1   \"Forever Captain Poodaman\" The Ahmad Butler Fo...  48-07-16  843800926   \n",
       "2                            \"Incredibly Blessed\" Inc  49-54-61  842071758   \n",
       "3                  \"R\" S.U.C.C.E.S.S. Foundation Inc.  49-06-59  874012670   \n",
       "4                                  \"Studio 5404\" Inc.  44-39-58  463180470   \n",
       "5                       \"THEY ARE HAITIAN\" FUND, INC.  20-63-46  300170128   \n",
       "6                                      \"Y\" Dive, Inc.  48-45-01  854252095   \n",
       "7   (ASMA) American Syrian Multicultural Associati...  42-84-63  273130182   \n",
       "8                                        #FeedHamburg  48-37-35  854150318   \n",
       "9                                   #HicksStrong Inc.  48-10-48  842612081   \n",
       "10                               #WalkAway Foundation  47-15-80  832820906   \n",
       "11                                04/11 10:17 PM test  47-13-95  206256427   \n",
       "12                                1/20/21 Action Fund  46-99-13  832210730   \n",
       "13                            10/40 Connections, Inc.  45-70-15  621825230   \n",
       "14                             1000 Feet Project, Inc  45-00-14  473820859   \n",
       "15                          1000 Islands Hose Haulers  45-38-38  454570241   \n",
       "\n",
       "   Registrant Type           City State  \n",
       "1              NFP   PHILADELPHIA    PA  \n",
       "2              NFP  STATEN ISLAND    NY  \n",
       "3              NFP      ROCHESTER    NY  \n",
       "4              NFP     MASSAPAQUA    NY  \n",
       "5              NFP         HUDSON    NY  \n",
       "6              NFP   SAINT ALBANS    NY  \n",
       "7              NFP       BROOKLYN    NY  \n",
       "8              NFP        HAMBURG    NY  \n",
       "9              NFP   CLIFTON PARK    NY  \n",
       "10             NFP       CARLSBAD    CA  \n",
       "11             NFP         ALBANY    NY  \n",
       "12             NFP  SAN FRANCISCO    CA  \n",
       "13             NFP         HIXSON    TN  \n",
       "14             NFP       NEW YORK    NY  \n",
       "15             NFP       CARTHAGE    NY  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Load modules\n",
    "#!pip install webdriver-manager\n",
    "#!pip install awscli\n",
    "import awscli\n",
    "import boto3\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "####SCRAPE THE WEBSITE######\n",
    "###call the webdriver\n",
    "s=Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=s)\n",
    "\n",
    "#enter the url path that needs to be accessed by webdriver\n",
    "browser.get('https://www.charitiesnys.com/RegistrySearch/search_charities.jsp')\n",
    "\n",
    "#identify xpath of location to select element\n",
    "inputElement = browser.find_element(By.XPATH,'//*[@id=\"header\"]/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[2]/td[2]/input[1]') #identifies the location of the EIN element\n",
    "inputElement.send_keys('0') #sends the \"0\" as the search value for EIN \n",
    "inputElement1 = browser.find_element(By.XPATH,'//*[@id=\"header\"]/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[10]/td/input[1]').click() #instatiates the click of the search\n",
    "sleep(4) #allow for the page to load by adding a sleep element\n",
    "#identify the table to scrape\n",
    "table = browser.find_element(By.CSS_SELECTOR,'table.Bordered')\n",
    "sleep(1)\n",
    "#####CREATE DATE FRAME#####\n",
    "#create empty dataframe\n",
    "df =[]\n",
    "\n",
    "#loop through dataframe to export table\n",
    "\n",
    "\n",
    "# Loop through pages\n",
    "while True:\n",
    "    # Scraping table data\n",
    "    for row in table.find_elements(By.CSS_SELECTOR, 'tr'):\n",
    "        cols = df.append([cell.text for cell in row.find_elements(By.CSS_SELECTOR, 'td')])\n",
    "\n",
    "    # Check for the next page link and click if available\n",
    "    try:\n",
    "        page_link = WebDriverWait(browser, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html/body/div[2]/div/table/tbody/tr/td[3]/div/div/span[2]/a[9]'))\n",
    "        )\n",
    "        page_link.click()\n",
    "        # Wait for the next page to load\n",
    "        sleep(4)\n",
    "        table = browser.find_element(By.CSS_SELECTOR, 'table.Bordered')\n",
    "    except:\n",
    "        # Break the loop if the next page link is not found\n",
    "        break\n",
    "\n",
    "# Update dataframe with header \n",
    "df = pd.DataFrame(df, columns=[\"Organization Name\", \"NY Reg #\", \"EIN\", \"Registrant Type\", \"City\", \"State\"])\n",
    "df.dropna(inplace=True)\n",
    "df #let's have a look at the data before creating the CSV file and loading it into s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ebe66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded file to location: s3://database-update-bucket-m10-assignment-hegde-akarsha/charities_bureau_scrape_20240413012452.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "import io\n",
    "\n",
    "# Specify the S3 bucket name\n",
    "bucket_name = 'database-update-bucket-m10-assignment-hegde-akarsha'\n",
    "\n",
    "# Prepare CSV file name\n",
    "filename = 'charities_bureau_scrape_'  # Name of your group\n",
    "datetime = time.strftime(\"%Y%m%d%H%M%S\")  # Timestamp\n",
    "s3_key = f\"{filename}{datetime}.csv\"  # S3 key (filename)\n",
    "\n",
    "# Convert DataFrame to CSV string\n",
    "csv_buffer = df.to_csv(index=False)\n",
    "\n",
    "# Create an in-memory file-like object\n",
    "csv_bytes = io.BytesIO(csv_buffer.encode())\n",
    "\n",
    "# Upload CSV file to S3\n",
    "s3 = boto3.client('s3')\n",
    "s3.upload_fileobj(csv_bytes, bucket_name, s3_key)\n",
    "\n",
    "# Print success message\n",
    "print(\"Successfully uploaded file to location: s3://{}/{}\".format(bucket_name, s3_key))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa108c",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d6e93",
   "metadata": {},
   "source": [
    "\n",
    "- https://www.programiz.com/python-programming/working-csv-files\n",
    "- https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.create_bucket\n",
    "- https://realpython.com/python-boto3-aws-s3/\n",
    "- https://robertorocha.info/setting-up-a-selenium-web-scraper-on-aws-lambda-with-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
